{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cada9640",
   "metadata": {},
   "source": [
    "# Q1. What is the Filter method in feature selection, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17712ef",
   "metadata": {},
   "source": [
    "- A feature is an attribute that has an impact on a problem or is useful for the problem, and choosing the important features for the model is known as feature selection.\n",
    "\n",
    "\n",
    "Filter Method for Feature selection:\n",
    "    \n",
    "The filter method ranks each feature based on some uni-variate metric and then selects the highest-ranking features. Some of the uni-variate metrics are\n",
    "\n",
    "- variance: removing constant and quasi constant features\n",
    "- chi-square: used for classification. It is a statistical test of independence to determine the dependency of two variables.\n",
    "- correlation coefficients: removes duplicate features\n",
    "- Information gain or mutual information: assess the dependency of the independent variable in predicting the target variable. In other words, it determines the ability of the independent feature to predict the target variable\n",
    "\n",
    "\n",
    "- The features that meet or exceed a certain threshold are selected for use in the model, while the others are discarded reducing the risk of overfitting and improve the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850703e",
   "metadata": {},
   "source": [
    "# Q2. How does the Wrapper method differ from the Filter method in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac08aa",
   "metadata": {},
   "source": [
    "Wrapper Methods :\n",
    "    \n",
    "In wrapper methodology, selection of features is done by considering it as a search problem, in which different combinations are made, evaluated, and compared with other combinations. It trains the algorithm by using the subset of features iteratively.\n",
    "\n",
    "\n",
    "Filter Methods :\n",
    "    \n",
    "Filter Method, features are selected on the basis of statistics measures. This method does not depend on the learning algorithm and chooses the features as a pre-processing step.\n",
    "\n",
    "The filter method filters out the irrelevant feature and redundant columns from the model by using different metrics through ranking.\n",
    "\n",
    "The advantage of using filter methods is that it needs low computational time and does not overfit the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294943bf",
   "metadata": {},
   "source": [
    "# Q3. What are some common techniques used in Embedded feature selection methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e893b",
   "metadata": {},
   "source": [
    "Embedded method:\n",
    "    \n",
    "In embedded method, feature selection process is embedded in the learning or the model building phase. It is less computationally expensive than wrapper method and less prone to overfitting.\n",
    "\n",
    "- L1-Regularization:\n",
    "     \n",
    "            - L1 Regularization, also called a lasso regression, adds the “absolute value of magnitude” of the coefficient as a penalty term to the loss function.\n",
    "            \n",
    "            \n",
    "- Decision Tree-Based Methods :\n",
    "    \n",
    "            - Decision tree-based methods, such as Random Forest and Gradient Boosted Trees, are often used in embedded feature selection. These algorithms use decision trees to identify the most important features for the model, and remove less important features from subsequent trees.This process can help to select a subset of relevant features while improving the accuracy of the model.\n",
    "        \n",
    "        \n",
    "- Gradient Descent :\n",
    "    \n",
    "            - Gradient descent is an optimization algorithm that's used when training a machine learning model. It's based on a convex function and tweaks its parameters iteratively to minimize a given function to its local minimum.\n",
    "  \n",
    "- Principal Component Analysis(PCA):\n",
    "    \n",
    "            - Principal Component Analysis (PCA) is a popular linear feature extractor used for unsupervised feature selection based on eigenvectors analysis to identify critical original features for principal component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5773e229",
   "metadata": {},
   "source": [
    "# Q4. What are some drawbacks of using the Filter method for feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3627fcd",
   "metadata": {},
   "source": [
    "The drawbacks of Filter Methods are:\n",
    "    \n",
    "    \n",
    "    - No interaction with classification model for feature selection.\n",
    "    \n",
    "    - Mostly ignores feature dependencies and considers each feature separately incase of univariate techniques,which may lead to low computational performance as compared to othertechniques of feature selection.\n",
    "    \n",
    "    - Redundancy\n",
    "    \n",
    "    - Parameter Tunning\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5989dc",
   "metadata": {},
   "source": [
    "# Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f42de1",
   "metadata": {},
   "source": [
    "- Filter methods are much faster compared to wrapper methods as they do not involve training the models. On the other hand, wrapper methods are computationally very expensive as well. Filter methods use statistical methods for evaluation of a subset of features while wrapper methods use cross validation.\n",
    "\n",
    "\n",
    "- For large data you should use the Filter approaches because these approaches are rapid and for small size of data it is better to use Wrapper (KNN, SVM,...) approaches because they are slower than the Filter approaches. or you can combine the two approaches to have better results than the two approaches.\n",
    "\n",
    "- Low variance and Feature Ranking and Model Agnostic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0ce91",
   "metadata": {},
   "source": [
    "# Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn. You are unsure of which features to include in the model because the dataset contains several different ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37148ab6",
   "metadata": {},
   "source": [
    "- To Find Most Pertinent attributes for the model using Filter Methods are:\n",
    "    \n",
    "    1- Collect The data.\n",
    "    \n",
    "    2- Preprocess data (convert columns to appropriate formats, handle missing values, etc.)\n",
    "\n",
    "    3- Conduct appropriate exploratory analysis to extract useful insights (whether directly useful for business or for eventual modelling/feature engineering).\n",
    "    \n",
    "    4- Derive new features.\n",
    "    \n",
    "    5- Reduce the number of variables using PCA.\n",
    "\n",
    "    6- Train a variety of models, tune model hyperparameters, etc. (handle class imbalance using appropriate techniques).\n",
    "\n",
    "    7- Evaluate the models using appropriate evaluation metrics. Note that it is more important to identify churners than the non-churners accurately - choose an appropriate evaluation metric which reflects this business goal.\n",
    "\n",
    "    8- Finally, choose a model based on some evaluation metric.\n",
    "    \n",
    "    9- Interpret the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4dbf82",
   "metadata": {},
   "source": [
    "# Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with many features, including player statistics and team rankings. Explain how you would use the Embedded method to select the most relevant features for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5dc85",
   "metadata": {},
   "source": [
    "1- Preprocess the dataset :\n",
    "    \n",
    "    - As with any machine learning project, the first step is to preprocess the dataset.\n",
    "\n",
    "    - This involves handling missing values, encoding categorical variables, and normalizing or standardizing numerical variables.\n",
    "\n",
    "2- Split the dataset:\n",
    "    \n",
    "    - Split the dataset into training and validation sets.\n",
    "\n",
    "    - The training set will be used to train the model, while the validation set will be used to evaluate the performance of the model.\n",
    "\n",
    "3- Choose a machine learning algorithm:\n",
    "    \n",
    "    - Select a machine learning algorithm that is suitable for the task of predicting the outcome of a soccer match.\n",
    "\n",
    "    - Examples are logistic regression, support vector machines, or random forest.\n",
    "\n",
    "4- Train the model with all features :\n",
    "    \n",
    "\n",
    "    -Train the model with all the available features in the training set.\n",
    "\n",
    "    - This will create a baseline model that we can use to compare the performance of the feature selection process.\n",
    "\n",
    "5- Use feature selection :\n",
    "    \n",
    "    - Use feature selection methods that are embedded within the model to select the most relevant features.\n",
    "\n",
    "    - Examples are LASSO regression, ridge regression, and elastic net regression. These methods penalize the coefficients of the features, leading to automatic feature selection.\n",
    "\n",
    "6- Evaluate the performance :\n",
    "    \n",
    "    - Evaluate the performance of the model on the validation set using appropriate performance metrics such as accuracy, precision, recall, and F1-score.\n",
    "\n",
    "7- Refine the feature set :\n",
    "    \n",
    "    - If the performance of the model is not satisfactory, refine the feature set by adjusting the regularization parameter or exploring other feature selection methods.\n",
    "\n",
    "8- Interpret the results:\n",
    "    \n",
    "    - Finally, interpret the results to gain insights into the factors that contribute to the outcome of a soccer match and develop strategies to improve the team's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fdaf5e",
   "metadata": {},
   "source": [
    "# Q8. You are working on a project to predict the price of a house based on its features, such as size, location, and age. You have a limited number of features, and you want to ensure that you select the most important ones for the model. Explain how you would use the Wrapper method to select the best set of features for the predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4134aa",
   "metadata": {},
   "source": [
    "\n",
    "1- Preprocess the dataset :\n",
    "    \n",
    "    - As with any machine learning project, the first step is to preprocess the dataset.\n",
    "\n",
    "    - This involves handling missing values, encoding categorical variables, and normalizing or standardizing numerical variables.\n",
    "\n",
    "2- Split the dataset :\n",
    "    \n",
    "    - Split the dataset into training and validation sets.\n",
    "\n",
    "    - The training set will be used to train the model, while the validation set will be used to evaluate the performance of the model.\n",
    "\n",
    "3- Choose a machine learning algorithm :\n",
    "    \n",
    "    - Select a machine learning algorithm that is suitable for the task of predicting the price of a house.\n",
    "    \n",
    "    - Examples are linear regression, decision trees, or support vector machines.\n",
    "\n",
    "4- Define the search space :\n",
    "    \n",
    "    - Define the search space for the Wrapper method. This is the space of all possible subsets of features.\n",
    "\n",
    "    - For example, if we have three features (size, location, and age), the search space would consist of eight possible subsets: {size}, {location}, {age}, {size, location}, {size, age}, {location, age}, {size, location, age}, and the empty set.\n",
    "\n",
    "5 -Train and test the model on each subset :\n",
    "    \n",
    "    - Train and test the model on each subset in the search space.\n",
    "\n",
    "    - This involves training the model on the training set with the selected subset of features and evaluating the performance of the model on the validation set using appropriate performance metrics such as mean squared error (MSE) or root mean squared error (RMSE).\n",
    "\n",
    "6- Select the best subset of features :\n",
    "    \n",
    "    - Select the subset of features that gives the best performance on the validation set. This is the subset that has the lowest MSE or RMSE.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e833d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
